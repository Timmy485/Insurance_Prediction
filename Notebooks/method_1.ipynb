{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2c41dcc",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yeboa\\AppData\\Local\\Temp\\ipykernel_4372\\3105957950.py:3: DeprecationWarning: `import pandas_profiling` is going to be deprecated by April 1st. Please use `import ydata_profiling` instead.\n",
      "  import pandas_profiling\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_profiling\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import classification_report, roc_auc_score, mean_absolute_error, accuracy_score, confusion_matrix, roc_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso, LassoCV, LogisticRegression\n",
    "import category_encoders as ce\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils import class_weight\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "daa9fa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df = pd.read_csv('train_data.csv')\n",
    "df_test = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d2362a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = df_test['Customer Id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0d0a08",
   "metadata": {},
   "source": [
    "- Customer ID dropped\n",
    "- Number of windows dropped\n",
    "- Garden imputed with V if settlement is urban and O otherwise\n",
    "- Building dimension of urban and rural settlements is assumed to be diff. \n",
    "    - Impute mean val for urban and rural settlements for missing data\n",
    "- Date of occupancy imputed with mean\n",
    "- Geo Code col dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4dba0a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, filename):\n",
    "    # drop ID col \n",
    "    df = df.drop('Customer Id', axis=1)\n",
    "\n",
    "    \n",
    "    # drop number of windows\n",
    "    df = df.drop('NumberOfWindows', axis=1)\n",
    "    \n",
    "    \n",
    "    # impute garden based on settlement\n",
    "    df.loc[df.Settlement == 'U', 'Garden'] = 'V'\n",
    "    df.loc[df.Settlement != 'U', 'Garden'] = 'O'\n",
    "    \n",
    "    \n",
    "    # impute building dimension\n",
    "    rural_dim = df[df['Settlement'] == 'R']\n",
    "    rural_dim_mean = rural_dim[\"Building Dimension\"].mean()\n",
    "    urban_dim = df[df['Settlement'] == 'U']\n",
    "    urban_dim_mean = urban_dim[\"Building Dimension\"].mean()\n",
    "    for i in range(len(df.Settlement)):\n",
    "        if (df.Settlement[i] == 'U') and pd.isnull(df['Building Dimension'][i]):\n",
    "            df.at[i, 'Building Dimension'] = urban_dim_mean\n",
    "        elif (df.Settlement[i] == 'R') and pd.isnull(df['Building Dimension'][i]):\n",
    "            df.at[i, 'Building Dimension'] = rural_dim_mean\n",
    "        \n",
    "        \n",
    "    #replace occupancy NaN values with mode date\n",
    "    date_mode = df.Date_of_Occupancy.mode()[0]\n",
    "    df.Date_of_Occupancy.fillna(date_mode, inplace=True)\n",
    "    df['Date_of_Occupancy'] = df['Date_of_Occupancy'].astype(int)\n",
    "    \n",
    "    \n",
    "    # Convert the numerical values to string labels for building type\n",
    "    mapping = {1: 'type1', 2: 'type2', 3: 'type3', 4: 'type4'}\n",
    "    df['Building_Type'] = df['Building_Type'].map(mapping)\n",
    "    \n",
    "    # drop geo code\n",
    "    df = df.drop('Geo_Code', axis=1)\n",
    "    \n",
    "    # save df\n",
    "    df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "69b45edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess(df, 'train_clean.csv')\n",
    "preprocess(df_test, 'test_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be15c7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_clean.csv')\n",
    "df_test = pd.read_csv('test_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "20f9ec9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insured_Period</th>\n",
       "      <th>Residential</th>\n",
       "      <th>Building Dimension</th>\n",
       "      <th>Building_Painted_V</th>\n",
       "      <th>Building_Fenced_V</th>\n",
       "      <th>Garden_V</th>\n",
       "      <th>Settlement_U</th>\n",
       "      <th>Building_Type_type2</th>\n",
       "      <th>Building_Type_type3</th>\n",
       "      <th>Building_Type_type4</th>\n",
       "      <th>Occupancy_Period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.352438</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.608342</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.205468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.339964</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.608342</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.340073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.524508</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.390181</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.205468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.352438</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.116367</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.723872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.352438</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.116367</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.634135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3064</th>\n",
       "      <td>0.352438</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.044457</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.987306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3065</th>\n",
       "      <td>0.352438</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.044457</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.699019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3066</th>\n",
       "      <td>0.352438</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.044457</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.320057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3067</th>\n",
       "      <td>0.352438</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.044457</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.384404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3068</th>\n",
       "      <td>0.352438</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.044457</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.609283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3069 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Insured_Period  Residential  Building Dimension  Building_Painted_V  \\\n",
       "0           0.352438            0           -0.608342                   1   \n",
       "1           0.339964            0           -0.608342                   1   \n",
       "2          -2.524508            0           -0.390181                   1   \n",
       "3           0.352438            0           -0.116367                   1   \n",
       "4           0.352438            0           -0.116367                   1   \n",
       "...              ...          ...                 ...                 ...   \n",
       "3064        0.352438            0           -0.044457                   1   \n",
       "3065        0.352438            0           -0.044457                   1   \n",
       "3066        0.352438            0           -0.044457                   1   \n",
       "3067        0.352438            0           -0.044457                   1   \n",
       "3068        0.352438            0           -0.044457                   1   \n",
       "\n",
       "      Building_Fenced_V  Garden_V  Settlement_U  Building_Type_type2  \\\n",
       "0                     0         0             0                    0   \n",
       "1                     0         0             0                    0   \n",
       "2                     1         1             1                    0   \n",
       "3                     0         0             0                    0   \n",
       "4                     0         0             0                    0   \n",
       "...                 ...       ...           ...                  ...   \n",
       "3064                  1         1             1                    0   \n",
       "3065                  1         1             1                    1   \n",
       "3066                  1         1             1                    1   \n",
       "3067                  1         1             1                    0   \n",
       "3068                  1         1             1                    1   \n",
       "\n",
       "      Building_Type_type3  Building_Type_type4  Occupancy_Period  \n",
       "0                       0                    0          0.205468  \n",
       "1                       0                    0          0.340073  \n",
       "2                       0                    0          0.205468  \n",
       "3                       0                    0         -1.723872  \n",
       "4                       0                    0         -1.634135  \n",
       "...                   ...                  ...               ...  \n",
       "3064                    0                    1          2.987306  \n",
       "3065                    0                    0          0.699019  \n",
       "3066                    0                    0         -1.320057  \n",
       "3067                    0                    0          7.384404  \n",
       "3068                    0                    0          0.609283  \n",
       "\n",
       "[3069 rows x 11 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_encode = ['Building_Painted', 'Building_Fenced', 'Garden', 'Settlement', 'Building_Type']\n",
    "# Perform one-hot encoding on cols\n",
    "df_test = pd.get_dummies(df_test, columns=cols_to_encode, prefix=cols_to_encode, drop_first=True)\n",
    "\n",
    "\n",
    "df_test['Occupancy_Period'] = df_test['YearOfObservation'] - df_test['Date_of_Occupancy']\n",
    "df_test = df_test.drop(columns=['YearOfObservation', 'Date_of_Occupancy'], axis=1)\n",
    "\n",
    "\n",
    "# instantiate the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# define columns to scale\n",
    "cols_to_scale = ['Insured_Period', 'Building Dimension', 'Occupancy_Period']\n",
    "\n",
    "# fit and transform the training set\n",
    "df_test[cols_to_scale] = scaler.fit_transform(df_test[cols_to_scale])\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d495c275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d17e3938",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('Claim', axis=1), df['Claim'], test_size=0.2, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fd8eee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_encode = ['Building_Painted', 'Building_Fenced', 'Garden', 'Settlement', 'Building_Type']\n",
    "\n",
    "# Perform one-hot encoding on cols\n",
    "X_train = pd.get_dummies(X_train, columns=cols_to_encode, prefix=cols_to_encode, drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, columns=cols_to_encode, prefix=cols_to_encode, drop_first=True)\n",
    "\n",
    "\n",
    "X_train['Occupancy_Period'] = X_train['YearOfObservation'] - X_train['Date_of_Occupancy']\n",
    "X_test['Occupancy_Period'] = X_test['YearOfObservation'] - X_test['Date_of_Occupancy']\n",
    "X_train = X_train.drop(columns=['YearOfObservation', 'Date_of_Occupancy'], axis=1)\n",
    "X_test = X_test.drop(columns=['YearOfObservation', 'Date_of_Occupancy'], axis=1)\n",
    "\n",
    "\n",
    "# instantiate the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# define columns to scale\n",
    "cols_to_scale = ['Insured_Period', 'Building Dimension', 'Occupancy_Period']\n",
    "\n",
    "# fit and transform the training set\n",
    "X_train[cols_to_scale] = scaler.fit_transform(X_train[cols_to_scale])\n",
    "\n",
    "# transform the test set using the fitted scaler from the training set\n",
    "X_test[cols_to_scale] = scaler.transform(X_test[cols_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "481fb1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_results(final_model, X_test, y_pred):\n",
    "    # Predict the probabilities of the test set\n",
    "    y_prob = final_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Compute the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Plot the confusion matrix\n",
    "    plt.imshow(cm, cmap=plt.cm.Blues)\n",
    "    plt.colorbar()\n",
    "    \n",
    "    # Add the number of values in each cell of the confusion matrix\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, cm[i, j],\n",
    "                     horizontalalignment='center',\n",
    "                     verticalalignment='center')\n",
    "            \n",
    "    plt.title('Confusion matrix')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xticks([0, 1], ['Negative', 'Positive'])\n",
    "    plt.yticks([0, 1], ['Negative', 'Positive'])\n",
    "    plt.show()\n",
    "\n",
    "    # Compute the ROC curve and ROC AUC score\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Plot the ROC curve\n",
    "    plt.plot(fpr, tpr, lw=1, label='ROC (AUC = %0.2f)' % (roc_auc))\n",
    "    plt.plot([0, 1], [0, 1], '--', color='gray', label='Random')\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4d15c198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgboost_model(X_train, y_train, X_test, output_file, df_test):\n",
    "    # Define the XGBoost model\n",
    "    xgb_model = XGBClassifier()\n",
    "\n",
    "    # Define the parameter grid to search over\n",
    "    params = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.1, 0.5]\n",
    "    }\n",
    "\n",
    "    # Define the grid search object\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=xgb_model, \n",
    "        param_grid=params, \n",
    "        scoring='roc_auc', \n",
    "        cv=5, \n",
    "#         refit='roc_auc', \n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Fit the grid search object to the data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best parameters and best score\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "\n",
    "    # Train an XGBoost model with the best parameters\n",
    "    xgb_model_best = XGBClassifier(**best_params)\n",
    "    xgb_model_best.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the test set\n",
    "    y_pred = xgb_model_best.predict(X_test)\n",
    "    submission_pred = xgb_model_best.predict(df_test) \n",
    "    results = pd.DataFrame(list(zip(ids, submission_pred)), columns=['Customer Id', 'Claim'])\n",
    "    results.to_csv(output_file, index=False)\n",
    "    \n",
    "    # Print the best parameters and best score\n",
    "    print('Best parameters: ', best_params)\n",
    "    print('Best score: ', best_score)\n",
    "    \n",
    "    # Print the classification report\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Print the roc_score report   \n",
    "    print(f'ROC_AUC_SCORE: {roc_auc_score(y_test, y_pred)}')\n",
    "    \n",
    "#     analyze_results(xgb_model_best, X_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f1e74568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "\n",
    "# Fit and transform the data\n",
    "X_train_sm_resampled, y_train_sm_resampled = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6fa35992",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 300}\n",
      "Best score:  0.8794892449414189\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.84      1098\n",
      "           1       0.46      0.37      0.41       334\n",
      "\n",
      "    accuracy                           0.75      1432\n",
      "   macro avg       0.64      0.62      0.63      1432\n",
      "weighted avg       0.74      0.75      0.74      1432\n",
      "\n",
      "ROC_AUC_SCORE: 0.619013339441336\n",
      "Submission Results: \n",
      " [1 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "train_xgboost_model(X_train_sm_resampled, y_train_sm_resampled, X_test, 'results.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3b28cb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform LassoCV to find the optimal alpha\n",
    "lasso = LassoCV(cv=5, random_state=42)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# extract the coefficients of the non-zero features\n",
    "coef = pd.Series(lasso.coef_, index=X_train.columns)\n",
    "selected_features = coef[coef != 0].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "183ea8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lasso, X_test_lasso = X_train[selected_features], X_test[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3672d4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "Best score:  0.7170229005349524\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.97      0.87      1098\n",
      "           1       0.62      0.17      0.27       334\n",
      "\n",
      "    accuracy                           0.78      1432\n",
      "   macro avg       0.71      0.57      0.57      1432\n",
      "weighted avg       0.75      0.78      0.73      1432\n",
      "\n",
      "ROC_AUC_SCORE: 0.5704329046824383\n"
     ]
    }
   ],
   "source": [
    "train_xgboost_model(X_train_lasso, y_train, X_test_lasso, 'lasso_results.txt', df_test[selected_features])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
