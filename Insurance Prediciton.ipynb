{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "704ea2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yeboa\\AppData\\Local\\Temp\\ipykernel_5560\\211589839.py:3: DeprecationWarning: `import pandas_profiling` is going to be deprecated by April 1st. Please use `import ydata_profiling` instead.\n",
      "  import pandas_profiling\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_profiling\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "import category_encoders as ce\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils import class_weight\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "014b88e0",
   "metadata": {},
   "source": [
    "# Phase 1: Data Cleaning + EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31645fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df93832e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Customer Id', axis=1)\n",
    "\n",
    "# replace . in NumberOfWindows with NaN\n",
    "df['NumberOfWindows'] = df['NumberOfWindows'].replace('   .', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a67549",
   "metadata": {},
   "outputs": [],
   "source": [
    "rural_settlement = df.loc[df.Settlement == 'R']\n",
    "rural_settlement.loc[rural_settlement.Garden == 'O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1072f6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_profile = pandas_profiling.ProfileReport(df)\n",
    "df_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb3a561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_vs_target(feature):\n",
    "    # YearOfObservation relation to number of claims\n",
    "    # Group the data by year and claim\n",
    "    grouped = df.groupby([feature, 'Claim']).size().reset_index(name='count')\n",
    "\n",
    "    # Pivot the data to create separate columns for 0 and 1 claims\n",
    "    pivoted = grouped.pivot(index=feature, columns='Claim', values='count')\n",
    "\n",
    "    # Plot a stacked bar chart\n",
    "    pivoted.plot(kind='bar', stacked=False)\n",
    "\n",
    "    # Set the plot title and axis labels\n",
    "    plt.title(f'Number of Claims by {feature}')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Count')\n",
    "\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ba1249",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_vs_target('YearOfObservation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad32a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_vs_target('Settlement')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb52942",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_vs_target('Building_Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f080943",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_vs_target('NumberOfWindows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42124b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "09f26098",
   "metadata": {},
   "source": [
    "## Insights\n",
    "1. All Urban settlements seem to have gardens\n",
    "2. Only 1 instance of rural settlement has a garden\n",
    "3. 99.6% of painted houses are in urban settlements\n",
    "4. All instances where Settlement is Urban has the number of windows reporting an NaN\n",
    "5. Target data is imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b4df48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#investigate relation between year of observation and target\n",
    "#investigate relation between date of occupancy and target"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d714c568",
   "metadata": {},
   "source": [
    "## NaN Values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fff0dfe7",
   "metadata": {},
   "source": [
    "### Number of windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0cdb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of windows imputation\n",
    "# highly correlated with Settlement & Garden\n",
    "df.NumberOfWindows.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5a2d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df.Settlement == 'U') & (df.NumberOfWindows.isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a217c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('NumberOfWindows', axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e52ce265",
   "metadata": {},
   "source": [
    "### Garden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ba9322",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.Garden.unique())\n",
    "df.loc[df.Garden.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.Settlement == 'U', 'Garden'] = 'V'\n",
    "df.loc[df.Settlement != 'U', 'Garden'] = 'O'\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "64beb319",
   "metadata": {},
   "source": [
    "### Building Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873bc5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Building Dimension'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150d42f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Settlement')['Building Dimension'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98b0d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rural_dim = df[df['Settlement'] == 'R']\n",
    "rural_dim_mean = rural_dim[\"Building Dimension\"].mean()\n",
    "urban_dim = df[df['Settlement'] == 'U']\n",
    "urban_dim_mean = urban_dim[\"Building Dimension\"].mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fbc45fed",
   "metadata": {},
   "source": [
    "Replace NaN of Building Settlement with mean of rural_dim_mean if its Settlement type is Rural 'R'.  \n",
    "Replace NaN of Building Settlement with mean of urban_dim_mean if its Settlement type is Urban 'U'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93aba502",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df.Settlement)):\n",
    "    if (df.Settlement[i] == 'U') and pd.isnull(df['Building Dimension'][i]):\n",
    "        df.at[i, 'Building Dimension'] = urban_dim_mean\n",
    "    elif (df.Settlement[i] == 'R') and pd.isnull(df['Building Dimension'][i]):\n",
    "        df.at[i, 'Building Dimension'] = rural_dim_mean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b01a9aae",
   "metadata": {},
   "source": [
    "### Date of Occupancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a545c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace NaN values with mode date\n",
    "date_mode = df.Date_of_Occupancy.mode()[0]\n",
    "df.Date_of_Occupancy.fillna(date_mode, inplace=True)\n",
    "\n",
    "df['Date_of_Occupancy'] = df['Date_of_Occupancy'].astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85d1d2ee",
   "metadata": {},
   "source": [
    "### Geo Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf4a34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Settlement')['Geo_Code'].apply(lambda x: x.mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d8a8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "rural_dim = df[df['Settlement'] == 'R']\n",
    "rural_dim_mean = rural_dim[\"Geo_Code\"].mode()[0]\n",
    "urban_dim = df[df['Settlement'] == 'U']\n",
    "urban_dim_mean = urban_dim[\"Geo_Code\"].mode()[0]\n",
    "\n",
    "for i in range(len(df.Settlement)):\n",
    "    if (df.Settlement[i] == 'U') and pd.isnull(df['Geo_Code'][i]):\n",
    "        df.at[i, 'Geo_Code'] = urban_dim_mean\n",
    "    elif (df.Settlement[i] == 'R') and pd.isnull(df['Geo_Code'][i]):\n",
    "        df.at[i, 'Geo_Code'] = rural_dim_mean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "efdb9e56",
   "metadata": {},
   "source": [
    "- Geo code has high cardinality  \n",
    "- One possible way to resolve this would be to engineer the locations/state of the codes into a diff col \n",
    "- For now Geo_Code is being dropped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb65fdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop Geo_Code\n",
    "df = df.drop('Geo_Code', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6fb2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_profile = pandas_profiling.ProfileReport(df)\n",
    "df_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b630e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df to train_clean.csv\n",
    "df.to_csv('train_clean.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c51fc839",
   "metadata": {},
   "source": [
    "# Phase 2: Feature Extraction & Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021b2500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the numerical values to string labels for building type\n",
    "mapping = {1: 'type1', 2: 'type2', 3: 'type3', 4: 'type4'}\n",
    "df['Building_Type'] = df['Building_Type'].map(mapping)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dcda9753",
   "metadata": {},
   "source": [
    "### Train Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b555573",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('Claim', axis=1), df['Claim'], test_size=0.2, random_state=42)  \n",
    "X_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9889b9dc",
   "metadata": {},
   "source": [
    "### Encode Categorical Cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfa3d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_encode = ['Building_Painted', 'Building_Fenced', 'Garden', 'Settlement', 'Building_Type']\n",
    "\n",
    "# Perform one-hot encoding on cols\n",
    "X_train = pd.get_dummies(X_train, columns=cols_to_encode, prefix=cols_to_encode)\n",
    "X_test = pd.get_dummies(X_test, columns=cols_to_encode, prefix=cols_to_encode)\n",
    "X_train\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf8e9ea7",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d4da9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train):\n",
    "    # Define the parameter grid to search over\n",
    "    param_grid = {'n_estimators': [50, 100, 200],\n",
    "                'max_depth': [3, 5, 10, None],\n",
    "                'min_samples_split': [2, 5, 10],\n",
    "                'min_samples_leaf': [1, 2, 4],\n",
    "                'max_features': ['sqrt', 'log2', None]}\n",
    "\n",
    "    # Create a RandomForestClassifier\n",
    "    rfc = RandomForestClassifier(random_state=42)\n",
    "\n",
    "    # Create a GridSearchCV object\n",
    "    grid_search = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1, scoring='roc_auc')\n",
    "\n",
    "    # Fit the GridSearchCV object to the data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Print the best hyperparameters and the corresponding score\n",
    "    print(\"Best parameters: \", grid_search.best_params_)\n",
    "    print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "    # Use the best hyperparameters to create a final model\n",
    "    final_model = RandomForestClassifier(**grid_search.best_params_, random_state=42)\n",
    "\n",
    "    # Fit the final model to the data\n",
    "    final_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the labels of the test set\n",
    "    y_pred = final_model.predict(X_test)\n",
    "\n",
    "    # Print the classification report\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a5b1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9034fc4c",
   "metadata": {},
   "source": [
    "### Create Building Occupancy Period (Years) Col"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "af0b55c7",
   "metadata": {},
   "source": [
    "Occupancy period represents how long people have been staying in a building from the first recorded occupancy to the year in which the insurance policy was created  \n",
    "Subtract Date_of_occupancy from YearOfObservation for new col  \n",
    "The assumption made here is that each insurance made here is for a unique house and the YearOfObservation was the very first time the building was insured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c8442b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['Occupancy_Period'] = X_train['YearOfObservation'] - X_train['Date_of_Occupancy']\n",
    "X_test['Occupancy_Period'] = X_test['YearOfObservation'] - X_test['Date_of_Occupancy']\n",
    "X_train = X_train.drop(columns=['YearOfObservation', 'Date_of_Occupancy'], axis=1)\n",
    "X_test = X_test.drop(columns=['YearOfObservation', 'Date_of_Occupancy'], axis=1)\n",
    "X_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "687d07c7",
   "metadata": {},
   "source": [
    "### Scale numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a49d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# define columns to scale\n",
    "cols_to_scale = ['Insured_Period', 'Building Dimension', 'Occupancy_Period']\n",
    "\n",
    "# fit and transform the training set\n",
    "X_train[cols_to_scale] = scaler.fit_transform(X_train[cols_to_scale])\n",
    "\n",
    "# transform the test set using the fitted scaler from the training set\n",
    "X_test[cols_to_scale] = scaler.transform(X_test[cols_to_scale])\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309c347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44b6a6af",
   "metadata": {},
   "source": [
    "### Fixing Data Imbalance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d29cc6e",
   "metadata": {},
   "source": [
    "#### Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c120b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "\n",
    "# Fit and transform the data\n",
    "X_train_sm_resampled, y_train_sm_resampled = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aff90d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(X_train_sm_resampled, y_train_sm_resampled)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "51930c94",
   "metadata": {},
   "source": [
    "#### Class Weight Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bc6c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique class labels in target variable\n",
    "classes = np.unique(y_train)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "\n",
    "# Create a dictionary with class weights\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [3, 5, 10, None],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4],\n",
    "            'max_features': ['sqrt', 'log2', None]}\n",
    "\n",
    "# Create a RandomForestClassifier\n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1, scoring='roc_auc')\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding score\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "# Use the best hyperparameters to create a final model\n",
    "final_model = RandomForestClassifier(**grid_search.best_params_, random_state=42)\n",
    "\n",
    "# Fit the final model to the data\n",
    "final_model.fit(X_train, y_train, class_weight=class_weights_dict)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "14e1eadd",
   "metadata": {},
   "source": [
    "### Utilizing LASSO for feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13f47cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # perform LassoCV to find the optimal alpha\n",
    "# lasso = LassoCV(cv=5, random_state=42)\n",
    "# lasso.fit(X_train, y_train)\n",
    "\n",
    "# # extract the coefficients of the non-zero features\n",
    "# coef = pd.Series(lasso.coef_, index=X_train.columns)\n",
    "# selected_features = coef[coef != 0].index.tolist()\n",
    "# selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb6ddf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test = X_train[selected_features], X_test[selected_features]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8af6e763",
   "metadata": {},
   "source": [
    "#### Tree Based Method for Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b31e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize the random forest classifier with default parameters\n",
    "# rfc = RandomForestClassifier()\n",
    "\n",
    "# # Fit the random forest classifier on the training data\n",
    "# rfc.fit(X_train, y_train)\n",
    "\n",
    "# # Get feature importances\n",
    "# importances = rfc.feature_importances_\n",
    "\n",
    "# # Sort feature importances in descending order\n",
    "# indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# # Print the feature ranking\n",
    "# print(\"Feature ranking:\")\n",
    "\n",
    "# for f in range(X_train.shape[1]):\n",
    "#     print(\"%d. %s (%f)\" % (f + 1, X_train.columns[indices[f]], importances[indices[f]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e48e40dfa26887012b26464b12de97565b3bff27290a8af1255245883a025ee5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
